<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>炼丹基础 | kingpoem的王国🏰</title><meta name="author" content="王俊琦"><meta name="copyright" content="王俊琦"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Numpy Pandas Matplotlib Scipy PyTorch Wandb Scikit-learn 的基础内容">
<meta property="og:type" content="article">
<meta property="og:title" content="炼丹基础">
<meta property="og:url" content="http://kingpoem.github.io/2024/11/11/alchemist-1/index.html">
<meta property="og:site_name" content="kingpoem的王国🏰">
<meta property="og:description" content="Numpy Pandas Matplotlib Scipy PyTorch Wandb Scikit-learn 的基础内容">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://kingpoem.github.io/images/alchemist_1/cover.png">
<meta property="article:published_time" content="2024-11-11T04:14:25.000Z">
<meta property="article:modified_time" content="2024-11-24T01:24:59.568Z">
<meta property="article:author" content="王俊琦">
<meta property="article:tag" content="学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kingpoem.github.io/images/alchemist_1/cover.png"><link rel="shortcut icon" href="/images/avatar.png"><link rel="canonical" href="http://kingpoem.github.io/2024/11/11/alchemist-1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: {"limitDay":600,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated.文章过期"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '炼丹基础',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-11-24 09:24:59'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/myStyle.css"><!-- hexo injector head_end start --><script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.esm.min.mjs">
    mermaid.initialize(
      startOnLoad: true,
    );
    </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/avatar.png" onerror="onerror=null;src='images/cover/cover_1.jpeg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('/./images/alchemist_1/cover.png')"><nav id="nav"><span id="blog-info"><a href="/" title="kingpoem的王国🏰"><span class="site-name">kingpoem的王国🏰</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">炼丹基础</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-11T04:14:25.000Z" title="发表于 2024-11-11 12:14:25">2024-11-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-24T01:24:59.568Z" title="更新于 2024-11-24 09:24:59">2024-11-24</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="炼丹基础"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>参考文献：<br><a target="_blank" rel="noopener" href="https://numpy.org.cn/user/quickstart.html">NumPy 中文文档</a> 用于 Python 的开源数值计算库<br><a target="_blank" rel="noopener" href="https://pandas.ac.cn/docs/getting_started/intro_tutorials/01_table_oriented.html">Pandas 中文文档</a> 数据处理库<br><a target="_blank" rel="noopener" href="https://matplotlib.org.cn/tutorials/index.html">Matplotlib 中文文档</a> 绘图库<br><a target="_blank" rel="noopener" href="https://seaborn.pydata.org/">Seaborn</a> 基于matplotlib的更好看的绘图库<br><a target="_blank" rel="noopener" href="https://docs.scipy.org.cn/doc/scipy/tutorial/index.html#user-guide">Scipy 中文文档</a> 构建在 NumPy 上的数学算法和函数的集合<br><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">PyTorch 官方文档</a> 深度学习框架<br><a target="_blank" rel="noopener" href="https://swanlab.cn/">SwanLab</a> 一站式跟踪、比较、分享模型<br><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/index.html">Scikit-learn</a> 机器学习<br><a target="_blank" rel="noopener" href="https://tqdm.github.io/">tqdm 进度条</a> 很方便的进度条<br><a target="_blank" rel="noopener" href="https://rich.readthedocs.io/en/stable/introduction.html#">rich</a> 更加好看的东西</p>
</blockquote>
<h2 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h2><h3 id="NDArray"><a href="#NDArray" class="headerlink" title="NDArray"></a>NDArray</h3><p>核心是多维数组。底层由C实现，效率高。</p>
<h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])                            <span class="comment"># 创建一个一维数组 arr1，包含元素 1 到 5</span></span><br><span class="line">arr2 = np.zeros([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.float32)                <span class="comment"># 创建一个形状为 (2, 2, 3) 的数组 arr2，元素全为 0，数据类型为 float32</span></span><br><span class="line">arr3 = np.ones([<span class="number">2</span>, <span class="number">2</span>])                                      <span class="comment"># 创建一个形状为 (2, 2) 的数组 arr3，元素全为 1</span></span><br><span class="line">arr4 = np.random.rand(<span class="number">2</span>, <span class="number">3</span>)                                 <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr4，元素为从 0 到 1 之间的随机数</span></span><br><span class="line">arr5 = np.random.randn(<span class="number">2</span>, <span class="number">3</span>)                                <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr5，元素为从标准正态分布中随机抽取的数</span></span><br><span class="line">arr6 = np.random.randint(<span class="number">0</span>, <span class="number">6</span>, size=(<span class="number">2</span>, <span class="number">3</span>))                 <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr6，元素为从 0 到 6 之间的随机整数</span></span><br><span class="line">arr7 = np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=(<span class="number">2</span>, <span class="number">3</span>))    <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr7，元素为从均值为 0、标准差为 1 的正态分布中随机抽取的数</span></span><br><span class="line">arr8 = np.random.random((<span class="number">2</span>, <span class="number">3</span>))                             <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr8，元素为从 0 到 1 之间的随机浮点数</span></span><br><span class="line">arr9 = np.random.uniform(low=<span class="number">0.0</span>, high=<span class="number">1.0</span>, size=(<span class="number">2</span>, <span class="number">3</span>))    <span class="comment"># 创建一个形状为 (2, 3) 的数组 arr9，元素为从 0 到 1 之间的均匀分布的随机浮点数</span></span><br><span class="line">arr10 = np.linspace(start=<span class="number">0</span>, stop=<span class="number">10</span>, num=<span class="number">5</span>, endpoint=<span class="literal">True</span>, dtype=np.int32)         <span class="comment"># 创建一个包含 5 个元素的数组 arr10，元素为从 0 到 10 之间的等差数列</span></span><br><span class="line">arr11 = np.logspace(start=<span class="number">0</span>, stop=<span class="number">10</span>, num=<span class="number">5</span>, endpoint=<span class="literal">True</span>, base=<span class="number">2.0</span>, dtype=np.float32)  <span class="comment"># 创建一个包含 5 个元素的数组 arr11，元素为从 2^0 到 2^10 之间的等比数列</span></span><br></pre></td></tr></table></figure>

<h3 id="修改合并"><a href="#修改合并" class="headerlink" title="修改合并"></a>修改合并</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.zeros([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>],  dtype=np.int32)</span><br><span class="line">arr2 = np.ones([<span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>], dtype=np.int32)</span><br><span class="line">arr = np.concatenate([arr1, arr2], axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;concatenate:&#x27;</span>, arr)</span><br></pre></td></tr></table></figure>

<h3 id="获取数组属性"><a href="#获取数组属性" class="headerlink" title="获取数组属性"></a>获取数组属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">10</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;size:&#x27;</span>, arr.size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape:&#x27;</span>, arr.shape)</span><br></pre></td></tr></table></figure>

<h3 id="切片和筛选"><a href="#切片和筛选" class="headerlink" title="切片和筛选"></a>切片和筛选</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>], </span><br><span class="line">                [<span class="number">4</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">9</span>],</span><br><span class="line">                [<span class="number">8</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], </span><br><span class="line">                [<span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>], </span><br><span class="line">                [<span class="number">9</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">10</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;single choose&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(arr[[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;slice&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(arr[:<span class="number">2</span>, :<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;filter&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(arr&gt;<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(arr[arr&gt;<span class="number">7</span>])</span><br></pre></td></tr></table></figure>

<h3 id="按条件选择、替换数据"><a href="#按条件选择、替换数据" class="headerlink" title="按条件选择、替换数据"></a>按条件选择、替换数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">condition = arr&gt;<span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(condition)</span><br><span class="line"><span class="built_in">print</span>(np.where(condition, -<span class="number">1</span>, arr))</span><br><span class="line"><span class="built_in">print</span>(np.where(condition, -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">rra = -arr</span><br><span class="line"><span class="built_in">print</span>(np.where(condition, arr, rra))</span><br></pre></td></tr></table></figure>

<h3 id="数据保存和加载"><a href="#数据保存和加载" class="headerlink" title="数据保存和加载"></a>数据保存和加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.save(file, arr, allow_pickle=<span class="literal">True</span>, fix_imports=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>file：要保存的文件，扩展名为 .npy，如果文件路径末尾没有扩展名 .npy，该扩展名会被自动加上。</li>
<li>arr: 要保存的数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.savez(file, *args, **kwds)</span><br></pre></td></tr></table></figure>
<ul>
<li>file：要保存的文件，扩展名为 .npz，如果文件路径末尾没有扩展名 .npz，该扩展名会被自动加上。</li>
<li>args: 要保存的数组，可以使用关键字参数为数组起一个名字，非关键字参数传递的数组会自动起名为 arr_0, arr_1, …　。</li>
<li>kwds: 要保存的数组使用关键字名称。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">b = np.array([[<span class="number">1</span>, <span class="number">9</span>, <span class="number">1</span>], [<span class="number">9</span>, <span class="number">8</span>, <span class="number">10</span>]])</span><br><span class="line"></span><br><span class="line">np.save(<span class="string">&quot;./a&quot;</span>, a)</span><br><span class="line">np.savez(<span class="string">&quot;./ab&quot;</span>, a=a, b=b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line">a = np.load(<span class="string">&#x27;./a.npy&#x27;</span>)</span><br><span class="line">ab = np.load(<span class="string">&#x27;./ab.npz&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(ab)</span><br><span class="line"><span class="built_in">print</span>(ab[<span class="string">&#x27;a&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h3><p>一种自动复制填充机制，使得原本形状不同的两个array能够进行原本只有两相同形状array才能进行的操作。</p>
<p>广播的规则如下：</p>
<ol>
<li>从后向前，如果两数组对应维度上轴的长度相同或其中一个的轴长度为1，广播兼容，可在轴长度为1的轴上进行广播机制处理。</li>
<li>如果两个数组的维度不同导致某个数组的前方没有维度，那么给低维度的数组前扩展提升一维，扩展维的轴长度为1,然后在扩展出的维上进行广播机制处理。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">a: (3, 5)</span></span><br><span class="line"><span class="string">b: (5)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. extend b into (1, 5)</span></span><br><span class="line"><span class="string">2. copy b in dim 0 to (3, 5)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = np.arange(<span class="number">1</span>, <span class="number">16</span>).reshape([<span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(a+b)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">2: ()</span></span><br><span class="line"><span class="string">a: (3, 5)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. extend 2 into (1)</span></span><br><span class="line"><span class="string">2. copy 2 in dim 0 to (5)</span></span><br><span class="line"><span class="string">3. extend 2 into (1, 5)</span></span><br><span class="line"><span class="string">4. copy 2 in dim 0 to (3, 5)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">1</span>, <span class="number">16</span>).reshape([<span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="number">2</span> * a)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">a: (1, 5)</span></span><br><span class="line"><span class="string">b: (3, 4, 1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. copy b in dim 2 to (3, 4, 5)</span></span><br><span class="line"><span class="string">2. copy a in dim 0 to (4, 5)</span></span><br><span class="line"><span class="string">3. extend a into (1, 4, 5)</span></span><br><span class="line"><span class="string">4. copy a in dim 0 to (3, 4, 5)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">b = np.arange(<span class="number">0</span>, <span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(a + b)</span><br></pre></td></tr></table></figure>

<h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵和向量积</span></span><br><span class="line">a = np.random.randint(<span class="number">5</span>, size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">b = np.random.randint(<span class="number">5</span>, size = (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;a:<span class="subst">&#123;a&#125;</span>\nb:<span class="subst">&#123;b&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dot根据不同情况选择，1维数组为内积，2维数组为矩阵乘，其他情况请阅读文档</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;dot:\n <span class="subst">&#123;np.dot(a, b)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># vdot计算逐元素乘积并求和</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;vdot:\n <span class="subst">&#123;np.vdot(a, b)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># inner 计算最后一维内积</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;inner:\n <span class="subst">&#123;np.inner(a, b)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 展开后算ab^T</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;outer:\n <span class="subst">&#123;np.outer(a, b)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># matmul计算矩阵乘</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;matmul:\n <span class="subst">&#123;a@b&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Einstein-Notation"><a href="#Einstein-Notation" class="headerlink" title="Einstein Notation"></a>Einstein Notation</h3><p>$$<br>a_i b_i &#x3D; \sum_{i} a_i b_i<br>$$</p>
<p>$$<br>a_{ij}b_{jk} &#x3D; \sum_{j}a_{ij}b_{jk}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(np.einsum(<span class="string">&quot;ij-&gt;ji&quot;</span>, a))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">A = torch.tensor(np.random.randint(<span class="number">5</span>, size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>))).reshape(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">B = torch.tensor(np.random.randint(<span class="number">5</span>, size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>))).reshape(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">想将两者的第2个维度分别reshape为2x1和1x2的两个向量，然后计算外积，得到一个2x2的kernel</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(A.shape, B.shape)</span><br><span class="line">res = torch.einsum(</span><br><span class="line">    <span class="string">&quot;ijk...,iko...-&gt;ijo...&quot;</span>, [A, B]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(res.shape)</span><br></pre></td></tr></table></figure>

<h3 id="NumPy-使用原则"><a href="#NumPy-使用原则" class="headerlink" title="NumPy 使用原则"></a>NumPy 使用原则</h3><p>尽量向量化所有操作，让numpy可以自动并行</p>
<ol>
<li>减少遍历操作</li>
<li>尽量使用内置方法和函数</li>
<li>善用广播</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line">a = np.array([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1919810</span>)])</span><br><span class="line"><span class="built_in">print</span>(time.time()-s_time)</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line">a = np.linspace(<span class="number">0</span>, <span class="number">1919810</span>, <span class="number">1919811</span>)</span><br><span class="line"><span class="built_in">print</span>(time.time() - s_time)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.random(<span class="number">1919810</span>)</span><br><span class="line">b = np.random.random(<span class="number">1919810</span>)</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line"><span class="built_in">print</span>(a@b)</span><br><span class="line"><span class="built_in">print</span>(time.time() - s_time)</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line">    res += a[i]*b[i]</span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"><span class="built_in">print</span>(time.time() - s_time)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">samples = np.random.random((<span class="number">1145</span>, <span class="number">14</span>))</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line"></span><br><span class="line">dists = []</span><br><span class="line"><span class="keyword">for</span> p1 <span class="keyword">in</span> samples:</span><br><span class="line">    <span class="keyword">for</span> p2 <span class="keyword">in</span> samples:</span><br><span class="line">        dists.append(np.linalg.norm(p1-p2))</span><br><span class="line"><span class="built_in">print</span>(np.mean(dists))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(time.time() - s_time)</span><br><span class="line"></span><br><span class="line">s_time = time.time()</span><br><span class="line"></span><br><span class="line">diff = samples[:, np.newaxis, :] - samples[np.newaxis, :, :]</span><br><span class="line">dist = np.linalg.norm(diff, axis = -<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(dist))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(time.time() - s_time)</span><br></pre></td></tr></table></figure>

<h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><h3 id="创建、读取、保存数据"><a href="#创建、读取、保存数据" class="headerlink" title="创建、读取、保存数据"></a><strong>创建、读取、保存数据</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, np.nan])</span><br><span class="line">s.tolist() <span class="comment"># 转为列表</span></span><br><span class="line">s.to_numpy() <span class="comment"># 转为 NumPy 数组</span></span><br><span class="line">s.to_dict() <span class="comment"># 转为字典</span></span><br><span class="line">data = &#123;<span class="string">&#x27;col1&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;col2&#x27;</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;file.csv&#x27;</span>)</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;file.xlsx&#x27;</span>, sheet_name=<span class="string">&#x27;Sheet1&#x27;</span>, header=<span class="number">0</span>, index_col=<span class="number">0</span>, skiprows=<span class="number">5</span>, convert_float=<span class="literal">True</span>, mangle_dupe_cols=<span class="literal">True</span>) <span class="comment"># 读取 Excel 文件, header指定行号, index_col指定列号, skiprows跳过前5行, convert_float转换为浮点数, mangle_dupe_cols处理重复列名</span></span><br><span class="line">df = pd.read_json(<span class="string">&#x27;data.json&#x27;</span>)</span><br><span class="line">df.to_csv(<span class="string">&#x27;output.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">df.to_excel(<span class="string">&#x27;output.xlsx&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h3 id="数据访问"><a href="#数据访问" class="headerlink" title="数据访问"></a><strong>数据访问</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">df.head() <span class="comment"># 查看 DataFrame 的前几行</span></span><br><span class="line">df.tail() <span class="comment"># 查看 DataFrame 的后几行</span></span><br><span class="line">df.info() <span class="comment"># 查看 DataFrame 的摘要信息</span></span><br><span class="line">df.describe() <span class="comment"># 查看 DataFrame 的统计摘要</span></span><br><span class="line">df.shape <span class="comment"># 查看 DataFrame 的维度</span></span><br><span class="line">df.columns <span class="comment"># 查看列名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择数据</span></span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>] <span class="comment"># 选择单列</span></span><br><span class="line">df[[<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>]] <span class="comment"># 选择多列</span></span><br><span class="line">element = df.iloc[<span class="number">0</span>, <span class="number">1</span>] <span class="comment"># 选择第一行第二列的元素</span></span><br><span class="line">df.loc[<span class="number">0</span>]   <span class="comment"># 按标签选择</span></span><br><span class="line">df[df[<span class="string">&#x27;col1&#x27;</span>] &gt; <span class="number">2</span>] <span class="comment"># 条件筛选</span></span><br></pre></td></tr></table></figure>

<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a><strong>数据清洗</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.isna().<span class="built_in">sum</span>() <span class="comment"># 查看缺失值</span></span><br><span class="line">df.fillna(<span class="number">0</span>) <span class="comment"># 填充缺失值</span></span><br><span class="line">df.dropna() <span class="comment"># 删除含有缺失值的行</span></span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>].fillna(df[<span class="string">&#x27;col1&#x27;</span>].mean(), inplace=<span class="literal">True</span>) <span class="comment"># 用列的均值填充缺失值</span></span><br><span class="line">df.drop_duplicates() <span class="comment"># 删除重复行</span></span><br><span class="line">df[df.duplicated()] <span class="comment"># 查找重复值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串操作</span></span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>] = df[<span class="string">&#x27;col1&#x27;</span>].<span class="built_in">str</span>.lower()  <span class="comment"># 转换为小写</span></span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>] = df[<span class="string">&#x27;col1&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&#x27;old&#x27;</span>, <span class="string">&#x27;new&#x27;</span>)  <span class="comment"># 字符替换</span></span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>] = df[<span class="string">&#x27;col1&#x27;</span>].<span class="built_in">str</span>.split()  <span class="comment"># 分割字符串</span></span><br><span class="line">elements = data[<span class="string">&#x27;Formula&#x27;</span>].<span class="built_in">str</span>.findall(pattern).apply(<span class="keyword">lambda</span> x: [<span class="keyword">match</span>[<span class="number">0</span>] <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> x])</span><br><span class="line">df.apply(<span class="keyword">lambda</span> row: row[<span class="string">&#x27;col1&#x27;</span>] + row[<span class="string">&#x27;col2&#x27;</span>], axis=<span class="number">1</span>) <span class="comment"># 对每一行应用一个函数</span></span><br><span class="line">df.apply(<span class="keyword">lambda</span> col: col.<span class="built_in">sum</span>(), axis=<span class="number">0</span>) <span class="comment"># 对每一列应用一个函数</span></span><br></pre></td></tr></table></figure>

<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a><strong>排序</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.sort_values(by=<span class="string">&#x27;col1&#x27;</span>) <span class="comment"># 按单列排序</span></span><br><span class="line">df.sort_values(by=[<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>], ascending=[<span class="literal">True</span>, <span class="literal">False</span>]) <span class="comment"># 按多列排序</span></span><br><span class="line">df.sort_index() <span class="comment"># 排序索引</span></span><br></pre></td></tr></table></figure>

<h3 id="合并"><a href="#合并" class="headerlink" title="合并"></a><strong>合并</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df1.merge(df2, on=<span class="string">&#x27;key&#x27;</span>) <span class="comment"># 合并两个 DataFrame</span></span><br><span class="line">df1.merge(df2, on=<span class="string">&#x27;key&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>) <span class="comment"># 左连接</span></span><br><span class="line">df_concat = pd.concat([df1, df2], axis=<span class="number">0</span>) <span class="comment"># 连接 DataFrame（按列）</span></span><br><span class="line">df_concat = pd.concat([df1, df2], axis=<span class="number">1</span>) <span class="comment"># 连接 DataFrame（按行）</span></span><br></pre></td></tr></table></figure>

<h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><h3 id="Matplotlib的核心概念"><a href="#Matplotlib的核心概念" class="headerlink" title="Matplotlib的核心概念"></a><strong>Matplotlib的核心概念</strong></h3><ul>
<li><p><strong>Figure</strong>：<code>Figure</code> 是整个图像的容器，包含了所有的图形元素，如子图（Axes）、标题、标签等。一个 <code>Figure</code> 对象可以包含多个 <code>Axes</code> 对象。</p>
</li>
<li><p><strong>Axes</strong>：<code>Axes</code> 是图形中的一个区域，包含坐标系、数据的可视化内容（如线条、点、柱状图等）。每个 <code>Axes</code> 可以有自己的坐标轴、标签和标题。</p>
</li>
<li><p><strong>Plot</strong>：<code>Plot</code> 是在 <code>Axes</code> 中显示的数据可视化内容。<code>Matplotlib</code> 提供了多种不同的 <code>plot</code> 类型，如线图、散点图、柱状图、直方图等。</p>
</li>
<li><p><strong>Axis</strong>：<code>Axis</code> 是坐标轴，用于定义图形的横坐标和纵坐标。每个 <code>Axes</code> 对象都包含两个 <code>Axis</code>，分别表示 x 轴和 y 轴。</p>
</li>
<li><p><strong>Artist</strong>：<code>Artist</code> 是 <code>Matplotlib</code> 中的基本对象，包括所有可以在图形上绘制的元素，例如文本、线条、矩形、坐标轴、标签等。</p>
</li>
</ul>
<h3 id="Matplotlib的常用函数"><a href="#Matplotlib的常用函数" class="headerlink" title="Matplotlib的常用函数"></a><strong>Matplotlib的常用函数</strong></h3><h4 id="基本绘图"><a href="#基本绘图" class="headerlink" title="基本绘图"></a>基本绘图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">y1 = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>]</span><br><span class="line">y2 = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建子图，1行2列</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">fig.suptitle(<span class="string">&#x27;图形标题&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">fig.subplots_adjust(top=<span class="number">0.85</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图形背景颜色</span></span><br><span class="line">fig.patch.set_facecolor(<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制第一个子图</span></span><br><span class="line">axs[<span class="number">0</span>].plot(x, y1, <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;平方值&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_title(<span class="string">&#x27;平方函数&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_xlabel(<span class="string">&#x27;x 轴&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;y 轴&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].grid(<span class="literal">True</span>)  <span class="comment"># 显示网格</span></span><br><span class="line">axs[<span class="number">0</span>].legend(</span><br><span class="line">    loc=<span class="string">&#x27;upper left&#x27;</span>,        <span class="comment"># 设置图例的位置为左上角</span></span><br><span class="line">    fontsize=<span class="number">12</span>,             <span class="comment"># 设置图例文本的字体大小为12</span></span><br><span class="line">    frameon=<span class="literal">False</span>,           <span class="comment"># 不显示图例的边框</span></span><br><span class="line">    title=<span class="string">&#x27;图例&#x27;</span>,           <span class="comment"># 设置图例的标题为&#x27;图例&#x27;</span></span><br><span class="line">    title_fontsize=<span class="number">12</span>,      <span class="comment"># 设置图例标题文本的字体大小为12</span></span><br><span class="line">    ncol=<span class="number">2</span>,                 <span class="comment"># 设置图例中的列数为2</span></span><br><span class="line">    shadow=<span class="literal">True</span>,            <span class="comment"># 添加阴影效果</span></span><br><span class="line">    bbox_to_anchor=(<span class="number">0.5</span>, <span class="number">1.15</span>),  <span class="comment"># 设置图例位置的锚点，(0.5, 1.15)表示相对于子图的位置</span></span><br><span class="line">    handlelength=<span class="number">2</span>,         <span class="comment"># 设置图例标识符的长度为2</span></span><br><span class="line">    handletextpad=<span class="number">1</span>         <span class="comment"># 设置图例标签与标识符之间的间距为1</span></span><br><span class="line">)</span><br><span class="line">axs[<span class="number">0</span>].set_facecolor(<span class="string">&#x27;white&#x27;</span>)  <span class="comment"># 设置子图背景颜色</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 x 轴和 y 轴的范围</span></span><br><span class="line">axs[<span class="number">0</span>].set_xlim(<span class="number">0</span>, <span class="number">6</span>)  <span class="comment"># x 轴范围从 0 到 6</span></span><br><span class="line">axs[<span class="number">0</span>].set_ylim(<span class="number">0</span>, <span class="number">30</span>)  <span class="comment"># y 轴范围从 0 到 30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度</span></span><br><span class="line">axs[<span class="number">0</span>].set_xticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">axs[<span class="number">0</span>].set_yticks([<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加标注</span></span><br><span class="line">axs[<span class="number">0</span>].annotate(<span class="string">&#x27;最大值&#x27;</span>, xy=(<span class="number">5</span>, <span class="number">25</span>), xytext=(<span class="number">4</span>, <span class="number">30</span>),</span><br><span class="line">                 arrowprops=<span class="built_in">dict</span>(facecolor=<span class="string">&#x27;black&#x27;</span>, shrink=<span class="number">0.05</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制第二个子图</span></span><br><span class="line">axs[<span class="number">1</span>].plot(x, y2, <span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;质数&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_title(<span class="string">&#x27;质数序列&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_xlabel(<span class="string">&#x27;x 轴&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;y 轴&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].grid(<span class="literal">True</span>)  <span class="comment"># 显示网格</span></span><br><span class="line">axs[<span class="number">1</span>].legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_facecolor(<span class="string">&#x27;white&#x27;</span>)  <span class="comment"># 设置子图背景颜色</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 x 轴和 y 轴的范围</span></span><br><span class="line">axs[<span class="number">1</span>].set_xlim(<span class="number">0</span>, <span class="number">6</span>)  <span class="comment"># x 轴范围从 0 到 6</span></span><br><span class="line">axs[<span class="number">1</span>].set_ylim(<span class="number">0</span>, <span class="number">12</span>)  <span class="comment"># y 轴范围从 0 到 12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度</span></span><br><span class="line">axs[<span class="number">1</span>].set_xticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">axs[<span class="number">1</span>].set_yticks([<span class="number">0</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整布局</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line">plt.savefig(<span class="string">&#x27;plot.png&#x27;</span>)  <span class="comment"># 保存图形为PNG文件</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>plt.legend()</code> 显示 label 图例, 应放在 label 之后设置</li>
<li><code>plt.xlabel</code>适用于简单情况, <code>ax.set_xlabel()</code>适用于复杂情况。</li>
<li><code>plt.xlim(0, 6)</code>设置 x 轴显示范围，超出范围不可见</li>
</ul>
<h4 id="动态更新图形"><a href="#动态更新图形" class="headerlink" title="动态更新图形"></a>动态更新图形</h4><ul>
<li><strong><code>matplotlib.animation.FuncAnimation</code></strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.animation <span class="keyword">import</span> FuncAnimation</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">line, = ax.plot([], [], lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">    line.set_data([], [])</span><br><span class="line">    <span class="keyword">return</span> line,</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">animate</span>(<span class="params">i</span>):</span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">100</span>)</span><br><span class="line">    y = np.sin(x + i / <span class="number">10.0</span>)</span><br><span class="line">    line.set_data(x, y)</span><br><span class="line">    <span class="keyword">return</span> line,</span><br><span class="line"></span><br><span class="line">ani = FuncAnimation(fig, animate, init_func=init, frames=<span class="number">100</span>, interval=<span class="number">20</span>, blit=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="3D-绘图"><a href="#3D-绘图" class="headerlink" title="3D 绘图"></a>3D 绘图</h4><ul>
<li><strong><code>matplotlib.pyplot.axes(projection=&#39;3d&#39;)</code></strong><br>用于创建 3D 绘图。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot(x, y, z)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplot_mosaic([[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;right&#x27;</span>],[<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;right&#x27;</span>]],figsize=(<span class="number">3</span>,<span class="number">4</span>), layout = <span class="string">&#x27;constrained&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> ax_name, ax <span class="keyword">in</span> axs.items():</span><br><span class="line">    ax.text(<span class="number">0.5</span>, <span class="number">0.5</span>, ax_name, ha = <span class="string">&#x27;center&#x27;</span>, va = <span class="string">&#x27;center&#x27;</span>, fontsize = <span class="number">18</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>), dpi=<span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = np.linspace(-np.pi, np.pi, <span class="number">30</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">C, S, T, A = np.cos(X), np.sin(X), np.arctan(X), np.arccos(X)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 绘制余弦曲线，使用蓝色的、连续的、宽度为 1 （像素）的线条</span></span><br><span class="line">plt.plot(X, C, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">1.0</span>, linestyle=<span class="string">&quot;-&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 绘制正弦曲线，使用绿色的、连续的、宽度为 1 （像素）的线条</span></span><br><span class="line">plt.plot(X, S, color=<span class="string">&quot;green&quot;</span>, linewidth=<span class="number">4.0</span>, linestyle=<span class="string">&quot;-.&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.scatter(X, T, color=<span class="string">&#x27;red&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.bar(X, T, color=<span class="string">&quot;yellow&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在屏幕上显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">X = np.linspace(-np.pi, np.pi, <span class="number">256</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">C, S = np.cos(X), np.sin(X)</span><br><span class="line"></span><br><span class="line">plt.plot(X, C, label = <span class="string">&#x27;sin&#x27;</span>)</span><br><span class="line">plt.plot(X, S, label=<span class="string">&#x27;cos&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改标签</span></span><br><span class="line">plt.xticks(</span><br><span class="line">    [-np.pi, -np.pi / <span class="number">2</span>, <span class="number">0</span>, np.pi / <span class="number">2</span>, np.pi],</span><br><span class="line">    [<span class="string">r&quot;$-\pi$&quot;</span>, <span class="string">r&quot;$-\pi/2$&quot;</span>, <span class="string">r&quot;$0$&quot;</span>, <span class="string">r&quot;$+\pi/2$&quot;</span>, <span class="string">r&quot;$+\pi$&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.yticks([-<span class="number">1</span>, <span class="number">0</span>, +<span class="number">1</span>], [<span class="string">r&quot;$-1$&quot;</span>, <span class="string">r&quot;$0$&quot;</span>, <span class="string">r&quot;$+1$&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改坐标轴位置</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&quot;right&quot;</span>].set_color(<span class="string">&quot;none&quot;</span>)</span><br><span class="line">ax.spines[<span class="string">&quot;top&quot;</span>].set_color(<span class="string">&quot;none&quot;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&quot;bottom&quot;</span>)</span><br><span class="line">ax.spines[<span class="string">&quot;bottom&quot;</span>].set_position((<span class="string">&quot;data&quot;</span>, <span class="number">0</span>))</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&quot;left&quot;</span>)</span><br><span class="line">ax.spines[<span class="string">&quot;left&quot;</span>].set_position((<span class="string">&quot;data&quot;</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图例</span></span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标注</span></span><br><span class="line">t = <span class="number">2</span> * np.pi / <span class="number">3</span></span><br><span class="line">plt.scatter(</span><br><span class="line">    [</span><br><span class="line">        t,</span><br><span class="line">    ],</span><br><span class="line">    [</span><br><span class="line">        np.sin(t),</span><br><span class="line">    ],</span><br><span class="line">    s=<span class="number">100</span>,</span><br><span class="line">    color=<span class="string">&quot;red&quot;</span>,</span><br><span class="line">)</span><br><span class="line">plt.annotate(</span><br><span class="line">    <span class="string">r&quot;$\sin(\frac&#123;2\pi&#125;&#123;3&#125;)=\frac&#123;\sqrt&#123;3&#125;&#125;&#123;2&#125;$&quot;</span>,</span><br><span class="line">    xy=(t, np.sin(t)),</span><br><span class="line">    xycoords=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    xytext=(+<span class="number">10</span>, +<span class="number">30</span>),</span><br><span class="line">    textcoords=<span class="string">&quot;offset points&quot;</span>,</span><br><span class="line">    arrowprops= <span class="built_in">dict</span>(arrowstyle = <span class="string">&quot;-&gt;&quot;</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><h3 id="查看模型内部变量"><a href="#查看模型内部变量" class="headerlink" title="查看模型内部变量"></a>查看模型内部变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> param.requires_grad:     <span class="comment"># 判断该参数是否需要计算梯度,即只有课训练的参数才会被打印</span></span><br><span class="line">        <span class="built_in">print</span>(name, param.shape)<span class="comment"># 打印参数名称和形状</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.sequential[<span class="number">0</span>],weight.shape) <span class="comment"># 打印第一个层的权重</span></span><br><span class="line"></span><br><span class="line">total_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total trainable parameters: <span class="subst">&#123;total_params&#125;</span>&quot;</span>)        <span class="comment"># 得出可训练参数的总数</span></span><br></pre></td></tr></table></figure>

<h3 id="线性层（nn-Linear）"><a href="#线性层（nn-Linear）" class="headerlink" title="线性层（nn.Linear）"></a><strong>线性层（<code>nn.Linear</code>）</strong></h3><p>线性层（全连接层）执行线性变换，通常用于多层感知器（MLP）模型中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入大小 3，输出大小 2</span></span><br><span class="line">linear_layer = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">3</span>)  <span class="comment"># 假设输入是 (1, 3) 的张量</span></span><br><span class="line">output_data = linear_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：计算 <code>y = xA^T + b</code>，其中 <code>A</code> 是权重矩阵，<code>b</code> 是偏置。</li>
</ul>
<h3 id="卷积层（nn-Conv2d）"><a href="#卷积层（nn-Conv2d）" class="headerlink" title="卷积层（nn.Conv2d）"></a><strong>卷积层（<code>nn.Conv2d</code>）</strong></h3><p>卷积层用于处理图像或其他网格数据。<code>nn.Conv2d</code> 是二维卷积层，通常用于图像分类和其他计算机视觉任务。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conv_layer = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)  <span class="comment"># 假设输入是 (1, 1, 28, 28) 的张量</span></span><br><span class="line">output_data = conv_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：通过卷积操作提取特征，通常应用于图像数据。</li>
</ul>
<h3 id="池化层（nn-MaxPool2d、nn-AvgPool2d）"><a href="#池化层（nn-MaxPool2d、nn-AvgPool2d）" class="headerlink" title="池化层（nn.MaxPool2d、nn.AvgPool2d）"></a><strong>池化层（<code>nn.MaxPool2d</code>、<code>nn.AvgPool2d</code>）</strong></h3><p>池化层用于下采样，减少特征图的空间维度（如宽度和高度），同时保持重要特征。常用的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">max_pool_layer = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_data = max_pool_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：最大池化通常选择池化区域中的最大值；平均池化选择池化区域中的平均值。</li>
</ul>
<h3 id="激活函数（nn-ReLU、nn-Sigmoid、nn-Tanh）"><a href="#激活函数（nn-ReLU、nn-Sigmoid、nn-Tanh）" class="headerlink" title="激活函数（nn.ReLU、nn.Sigmoid、nn.Tanh）"></a><strong>激活函数（<code>nn.ReLU</code>、<code>nn.Sigmoid</code>、<code>nn.Tanh</code>）</strong></h3><p>激活函数引入非线性特性，帮助模型捕捉复杂的模式。常用的激活函数包括 ReLU、Sigmoid 和 Tanh。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">relu = nn.ReLU()</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">output_data = relu(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>ReLU</strong>：<code>f(x) = max(0, x)</code>，常用于隐藏层。</li>
<li><strong>Sigmoid</strong>：<code>f(x) = 1 / (1 + exp(-x))</code>，常用于输出层（如二分类问题）。</li>
<li><strong>Tanh</strong>：<code>f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))</code>，输出范围为 (-1, 1)。</li>
</ul>
<h3 id="批归一化层（nn-BatchNorm2d）"><a href="#批归一化层（nn-BatchNorm2d）" class="headerlink" title="批归一化层（nn.BatchNorm2d）"></a><strong>批归一化层（<code>nn.BatchNorm2d</code>）</strong></h3><p>批归一化层用于加速训练并稳定模型，通过标准化每一层的输入，使其均值为 0，方差为 1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_norm = nn.BatchNorm2d(<span class="number">16</span>)  <span class="comment"># 16 是输入的通道数</span></span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">16</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_data = batch_norm(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：对每个小批量的输入进行归一化，确保训练过程中更稳定的梯度更新。</li>
</ul>
<h3 id="丢弃层（nn-Dropout）"><a href="#丢弃层（nn-Dropout）" class="headerlink" title="丢弃层（nn.Dropout）"></a><strong>丢弃层（<code>nn.Dropout</code>）</strong></h3><p>丢弃层用于防止过拟合。它在训练过程中随机将部分神经元的输出设置为 0，避免模型过于依赖某些特定的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dropout = nn.Dropout(p=<span class="number">0.5</span>)  <span class="comment"># 50% 的神经元会被丢弃</span></span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">output_data = dropout(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：丢弃率（<code>p</code>）定义了在每次前向传播时丢弃的神经元比例。</li>
</ul>
<h3 id="转置卷积层（nn-ConvTranspose2d）"><a href="#转置卷积层（nn-ConvTranspose2d）" class="headerlink" title="转置卷积层（nn.ConvTranspose2d）"></a><strong>转置卷积层（<code>nn.ConvTranspose2d</code>）</strong></h3><p>转置卷积层（也称为反卷积层）用于上采样操作，通常用于生成对抗网络（GAN）和图像生成模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conv_transpose_layer = nn.ConvTranspose2d(in_channels=<span class="number">16</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">16</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_data = conv_transpose_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：实现反向卷积（或上采样），用于恢复原始输入的空间分辨率。</li>
</ul>
<h3 id="嵌入层（nn-Embedding）"><a href="#嵌入层（nn-Embedding）" class="headerlink" title="嵌入层（nn.Embedding）"></a><strong>嵌入层（<code>nn.Embedding</code>）</strong></h3><p>嵌入层通常用于处理离散的输入数据（如单词、类别标签等），将其转换为连续的高维向量表示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">embedding = nn.Embedding(num_embeddings=<span class="number">10</span>, embedding_dim=<span class="number">5</span>)</span><br><span class="line">input_data = torch.LongTensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">output_data = embedding(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：将整数索引映射到固定维度的向量空间。</li>
</ul>
<h3 id="LSTM层（nn-LSTM）"><a href="#LSTM层（nn-LSTM）" class="headerlink" title="LSTM层（nn.LSTM）"></a><strong>LSTM层（<code>nn.LSTM</code>）</strong></h3><p>LSTM（长短期记忆）层用于处理序列数据，能够捕捉长程依赖关系。常用于自然语言处理（NLP）任务。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lstm_layer = nn.LSTM(input_size=<span class="number">10</span>, hidden_size=<span class="number">20</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">5</span>, <span class="number">3</span>, <span class="number">10</span>)  <span class="comment"># (sequence_length, batch_size, input_size)</span></span><br><span class="line">output_data, (h_n, c_n) = lstm_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：LSTM 层用于处理序列数据，能够有效地学习时间序列或语言模型中的长期依赖。</li>
</ul>
<h3 id="GRU层（nn-GRU）"><a href="#GRU层（nn-GRU）" class="headerlink" title="GRU层（nn.GRU）"></a><strong>GRU层（<code>nn.GRU</code>）</strong></h3><p>GRU（门控循环单元）是另一种用于序列数据处理的循环神经网络（RNN）层。与 LSTM 类似，GRU 也能捕捉序列中的长程依赖。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gru_layer = nn.GRU(input_size=<span class="number">10</span>, hidden_size=<span class="number">20</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">5</span>, <span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line">output_data, h_n = gru_layer(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：与 LSTM 类似，GRU 也是一种序列处理层，但结构上更简洁，计算效率更高。</li>
</ul>
<h3 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a><strong>自定义层</strong></h3><p>你还可以在 <code>PyTorch</code> 中创建自定义层，继承 <code>nn.Module</code> 并实现 <code>forward()</code> 方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyLayer, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.conv(x)</span><br><span class="line"></span><br><span class="line">my_layer = MyLayer(<span class="number">1</span>, <span class="number">16</span>)</span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_data = my_layer(input_data)</span><br></pre></td></tr></table></figure>

<h3 id="全局平均池化（nn-AdaptiveAvgPool2d）"><a href="#全局平均池化（nn-AdaptiveAvgPool2d）" class="headerlink" title="全局平均池化（nn.AdaptiveAvgPool2d）"></a><strong>全局平均池化（<code>nn.AdaptiveAvgPool2d</code>）</strong></h3><p>全局平均池化层通常用于模型最后，用于将特征图的每个通道池化成一个值（即全局平均）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">adaptive_avg_pool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># 输出大小是 (1, 1)</span></span><br><span class="line">input_data = torch.randn(<span class="number">1</span>, <span class="number">16</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">output_data = adaptive_avg_pool(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>功能</strong>：将特征图压缩为一个固定大小的输出。</li>
</ul>
<h2 id="Utils"><a href="#Utils" class="headerlink" title="Utils"></a>Utils</h2><h3 id="os-文件和目录操作"><a href="#os-文件和目录操作" class="headerlink" title="os - 文件和目录操作"></a><code>os</code> - 文件和目录操作</h3><ul>
<li><code>os.chdir</code>：改变当前工作目录。</li>
<li><code>os.path.join</code>：拼接路径。</li>
<li><code>os.path.splitext</code>：分离文件名和扩展名。</li>
<li><code>os.path.basename</code>：获取文件名。</li>
<li><code>os.path.dirname</code>：获取目录名。</li>
<li><code>os.path.expandvars</code>：展开环境变量。</li>
</ul>
<h3 id="join"><a href="#join" class="headerlink" title="join"></a><code>join</code></h3><p><code>join()</code> 是字符串对象的一个方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">str</span>.join(iterable) <span class="comment"># str 是用作连接符的字符串， iterable 可以是字符串、列表、元组等，其中包含要连接的字符串元素</span></span><br><span class="line"></span><br><span class="line">words = [<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;from&quot;</span>, <span class="string">&quot;Fitten&quot;</span>]</span><br><span class="line">result = <span class="string">&quot; &quot;</span>.join(words)  <span class="comment"># 用空格连接</span></span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出: Hello world from Fitten</span></span><br><span class="line"></span><br><span class="line">items = [<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;cherry&quot;</span>]</span><br><span class="line">result = <span class="string">&quot;, &quot;</span>.join(items)  <span class="comment"># 用逗号和空格连接</span></span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出: apple, banana, cherry</span></span><br><span class="line"></span><br><span class="line">chars = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]</span><br><span class="line">result = <span class="string">&quot;-&quot;</span>.join(chars)  <span class="comment"># 用连字符连接</span></span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出: a-b-c-d</span></span><br></pre></td></tr></table></figure>

<h3 id="zip"><a href="#zip" class="headerlink" title="zip"></a><code>zip</code></h3><p><code>zip()</code> 是 Python 内置函数，用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">list2 = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">zipped = <span class="built_in">zip</span>(list1, list2)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(zipped))  <span class="comment"># 输出: [(1, &#x27;a&#x27;), (2, &#x27;b&#x27;), (3, &#x27;c&#x27;)]</span></span><br><span class="line"></span><br><span class="line">names = [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Charlie&#x27;</span>]</span><br><span class="line">scores = [<span class="number">85</span>, <span class="number">90</span>, <span class="number">95</span>]</span><br><span class="line">paired = <span class="built_in">zip</span>(names, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(paired))  <span class="comment"># 输出: [(&#x27;Alice&#x27;, 85), (&#x27;Bob&#x27;, 90), (&#x27;Charlie&#x27;, 95)]</span></span><br><span class="line"></span><br><span class="line">list1 = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">list2 = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">result = <span class="built_in">zip</span>(list1, list2)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(result))  <span class="comment"># 输出: [(1, &#x27;a&#x27;), (2, &#x27;b&#x27;)]</span></span><br><span class="line"></span><br><span class="line">zipped = [(<span class="string">&#x27;Alice&#x27;</span>, <span class="number">85</span>), (<span class="string">&#x27;Bob&#x27;</span>, <span class="number">90</span>)]</span><br><span class="line">names, scores = <span class="built_in">zip</span>(*zipped)</span><br><span class="line"><span class="built_in">print</span>(names)  <span class="comment"># 输出: (&#x27;Alice&#x27;, &#x27;Bob&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(scores)  <span class="comment"># 输出: (85, 90)</span></span><br></pre></td></tr></table></figure>

<h3 id="swanlab"><a href="#swanlab" class="headerlink" title="swanlab"></a>swanlab</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> swanlab</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个新的swanlab run类来跟踪这个脚本</span></span><br><span class="line">swanlab.init(</span><br><span class="line">  <span class="comment"># 设置将记录此次运行的项目信息</span></span><br><span class="line">  project=<span class="string">&quot;Alchemist_1&quot;</span>,</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 跟踪超参数和运行元数据</span></span><br><span class="line">  config=&#123;</span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.02</span>,</span><br><span class="line">    <span class="string">&quot;architecture&quot;</span>: <span class="string">&quot;CNN&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dataset&quot;</span>: <span class="string">&quot;CIFAR-100&quot;</span>,</span><br><span class="line">    <span class="string">&quot;epochs&quot;</span>: <span class="number">10</span></span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟训练</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">offset = random.random() / <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, epochs):</span><br><span class="line">  acc = <span class="number">1</span> - <span class="number">2</span> ** -epoch - random.random() / epoch - offset</span><br><span class="line">  loss = <span class="number">2</span> ** -epoch + random.random() / epoch + offset</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 向swanlab上传训练指标</span></span><br><span class="line">  swanlab.log(&#123;<span class="string">&quot;acc&quot;</span>: acc, <span class="string">&quot;loss&quot;</span>: loss&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [可选] 完成训练，这在notebook环境中是必要的</span></span><br><span class="line">swanlab.finish()</span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">swanlab.restore(<span class="string">&quot;model.h5&quot;</span>)</span><br><span class="line"><span class="comment"># 清理所有实验数据</span></span><br><span class="line">swanlab.reset()</span><br></pre></td></tr></table></figure>

<p><code>wandb.Artifact</code> 是一种用于追踪、版本控制和共享数据的方式。它允许你记录、存储和共享数据集、模型、代码等对象。</p>
<ul>
<li>创建和保存一个 Artifact：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">artifact = wandb.Artifact(<span class="string">&quot;model&quot;</span>, <span class="built_in">type</span>=<span class="string">&quot;model&quot;</span>)</span><br><span class="line">artifact.add_file(<span class="string">&quot;model.h5&quot;</span>)</span><br><span class="line">wandb.log_artifact(artifact)</span><br></pre></td></tr></table></figure></li>
<li>获取并使用 Artifact：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">artifact = wandb.use_artifact(<span class="string">&quot;my-username/my-project/model:latest&quot;</span>)</span><br><span class="line">artifact.download()</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="pprint"><a href="#pprint" class="headerlink" title="pprint"></a>pprint</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;address&#x27;</span>: &#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;New York&#x27;</span>, <span class="string">&#x27;zip&#x27;</span>: <span class="string">&#x27;10001&#x27;</span>&#125;&#125;</span><br><span class="line">pprint(data)</span><br><span class="line">pprint(<span class="built_in">dir</span>(networkx),indent=<span class="number">4</span>,width=<span class="number">100</span>,compact=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>width 默认 80</p>
<p><code>PrettyPrinter()</code> 是 <code>pprint</code> 模块的一个类，允许你通过更多的自定义选项来创建一个格式化打印对象，然后调用它来打印数据。你可以通过这个类设置输出的最大深度、缩进级别等参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> PrettyPrinter</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>, <span class="string">&#x27;address&#x27;</span>: &#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;Los Angeles&#x27;</span>, <span class="string">&#x27;zip&#x27;</span>: <span class="string">&#x27;90001&#x27;</span>&#125;&#125;</span><br><span class="line">printer = PrettyPrinter(depth=<span class="number">2</span>)</span><br><span class="line">printer.pprint(data)</span><br></pre></td></tr></table></figure>

<h3 id="tqdm"><a href="#tqdm" class="headerlink" title="tqdm"></a>tqdm</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">100</span>), desc=<span class="string">&quot;Processing items&quot;</span>, unit=<span class="string">&quot;item&quot;</span>):</span><br><span class="line">    <span class="comment"># 执行某些操作</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p><code>tqdm</code> 允许你在多个嵌套循环中显示进度条。可以通过 <code>tqdm</code> 嵌套多次来显示不同层次的进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">5</span>), desc=<span class="string">&quot;Outer loop&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">100</span>), desc=<span class="string">&quot;Inner loop&quot;</span>, leave=<span class="literal">False</span>):</span><br><span class="line">        <span class="comment"># 执行某些操作</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>leave=False</code> 表示内层进度条完成后不保留在屏幕上。</li>
</ul>
<p>有时我们可能需要手动更新进度条，可以通过 <code>update()</code> 方法来更新进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pbar = tqdm(total=<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="comment"># 做一些事情</span></span><br><span class="line">    pbar.update(<span class="number">10</span>)  <span class="comment"># 每次更新进度</span></span><br><span class="line">pbar.close()</span><br></pre></td></tr></table></figure>

<h2 id="Scikit-learn"><a href="#Scikit-learn" class="headerlink" title="Scikit-learn"></a>Scikit-learn</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a><strong>数据预处理</strong></h3><h4 id="特征缩放和标准化"><a href="#特征缩放和标准化" class="headerlink" title="特征缩放和标准化"></a>特征缩放和标准化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化：均值为0，方差为1</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化：将数据缩放到 [0, 1]</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br></pre></td></tr></table></figure>

<h4 id="类别数据编码"><a href="#类别数据编码" class="headerlink" title="类别数据编码"></a>类别数据编码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标签编码：将类别标签转化为数字</span></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">y_encoded = encoder.fit_transform(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 独热编码：将类别数据转换为二进制（0/1）矩阵</span></span><br><span class="line">onehot_encoder = OneHotEncoder()</span><br><span class="line">y_onehot = onehot_encoder.fit_transform(y.reshape(-<span class="number">1</span>, <span class="number">1</span>)).toarray()</span><br></pre></td></tr></table></figure>

<h4 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充缺失值</span></span><br><span class="line">imputer = SimpleImputer(strategy=<span class="string">&#x27;mean&#x27;</span>)  <span class="comment"># &#x27;mean&#x27;, &#x27;median&#x27;, &#x27;most_frequent&#x27;</span></span><br><span class="line">X_imputed = imputer.fit_transform(X)</span><br></pre></td></tr></table></figure>

<h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, f_classif</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于卡方检验选择前k个最佳特征</span></span><br><span class="line">selector = SelectKBest(score_func=f_classif, k=<span class="number">5</span>)</span><br><span class="line">X_new = selector.fit_transform(X, y)</span><br></pre></td></tr></table></figure>

<h3 id="模型训练与预测"><a href="#模型训练与预测" class="headerlink" title="模型训练与预测"></a><strong>模型训练与预测</strong></h3><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机森林分类器</span></span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归分类器</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持向量机分类器</span></span><br><span class="line">model = SVC(kernel=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>

<h4 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用训练好的模型进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br></pre></td></tr></table></figure>

<h4 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用回归模型进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br></pre></td></tr></table></figure>

<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a><strong>模型评估</strong></h3><h4 id="评估回归模型"><a href="#评估回归模型" class="headerlink" title="评估回归模型"></a>评估回归模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算决定系数 R^2</span></span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br></pre></td></tr></table></figure>

<h4 id="评估分类模型"><a href="#评估分类模型" class="headerlink" title="评估分类模型"></a>评估分类模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, confusion_matrix, classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算混淆矩阵</span></span><br><span class="line">conf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出分类报告：包括精准率、召回率和F1值</span></span><br><span class="line">report = classification_report(y_test, y_pred)</span><br></pre></td></tr></table></figure>

<h4 id="ROC-曲线和-AUC"><a href="#ROC-曲线和-AUC" class="headerlink" title="ROC 曲线和 AUC"></a>ROC 曲线和 AUC</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算ROC曲线的FPR、TPR</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算AUC值</span></span><br><span class="line">roc_auc = auc(fpr, tpr)</span><br></pre></td></tr></table></figure>

<h3 id="交叉验证与模型选择"><a href="#交叉验证与模型选择" class="headerlink" title="交叉验证与模型选择"></a><strong>交叉验证与模型选择</strong></h3><h4 id="K折交叉验证"><a href="#K折交叉验证" class="headerlink" title="K折交叉验证"></a>K折交叉验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># K折交叉验证</span></span><br><span class="line">scores = cross_val_score(model, X, y, cv=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="网格搜索调参"><a href="#网格搜索调参" class="headerlink" title="网格搜索调参"></a>网格搜索调参</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数范围</span></span><br><span class="line">param_grid = &#123;<span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>], <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网格搜索</span></span><br><span class="line">grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取最佳参数</span></span><br><span class="line">best_params = grid_search.best_params_</span><br></pre></td></tr></table></figure>

<h4 id="随机搜索调参"><a href="#随机搜索调参" class="headerlink" title="随机搜索调参"></a>随机搜索调参</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机搜索</span></span><br><span class="line">random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=<span class="number">10</span>, cv=<span class="number">5</span>)</span><br><span class="line">random_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取最佳参数</span></span><br><span class="line">best_params = random_search.best_params_</span><br></pre></td></tr></table></figure>

<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a><strong>特征工程</strong></h3><h4 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 (PCA)"></a>主成分分析 (PCA)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主成分分析</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br></pre></td></tr></table></figure>

<h4 id="线性判别分析-LDA"><a href="#线性判别分析-LDA" class="headerlink" title="线性判别分析 (LDA)"></a>线性判别分析 (LDA)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性判别分析</span></span><br><span class="line">lda = LinearDiscriminantAnalysis(n_components=<span class="number">1</span>)</span><br><span class="line">X_lda = lda.fit_transform(X, y)</span><br></pre></td></tr></table></figure>

<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本特征提取（TF-IDF）</span></span><br><span class="line">vectorizer = TfidfVectorizer()</span><br><span class="line">X_tfidf = vectorizer.fit_transform(corpus)</span><br></pre></td></tr></table></figure>

<h3 id="模型持久化"><a href="#模型持久化" class="headerlink" title="模型持久化"></a><strong>模型持久化</strong></h3><h4 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型到文件</span></span><br><span class="line">joblib.dump(model, <span class="string">&#x27;model.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从文件加载模型</span></span><br><span class="line">model = joblib.load(<span class="string">&#x27;model.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="管道与组合"><a href="#管道与组合" class="headerlink" title="管道与组合"></a><strong>管道与组合</strong></h3><h4 id="使用管道"><a href="#使用管道" class="headerlink" title="使用管道"></a>使用管道</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个包含预处理和模型的管道</span></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;classifier&#x27;</span>, RandomForestClassifier())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练管道</span></span><br><span class="line">pipeline.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用管道进行预测</span></span><br><span class="line">y_pred = pipeline.predict(X_test)</span><br></pre></td></tr></table></figure>

<h3 id="其他常见方法"><a href="#其他常见方法" class="headerlink" title="其他常见方法"></a><strong>其他常见方法</strong></h3><h4 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取模型的特征重要性（对于决策树类模型）</span></span><br><span class="line">importances = model.feature_importances_</span><br></pre></td></tr></table></figure>

<h4 id="模型预测概率"><a href="#模型预测概率" class="headerlink" title="模型预测概率"></a>模型预测概率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取预测的类别概率</span></span><br><span class="line">y_pred_prob = model.predict_proba(X_test)</span><br></pre></td></tr></table></figure>

<h4 id="训练模型的过程显示"><a href="#训练模型的过程显示" class="headerlink" title="训练模型的过程显示"></a>训练模型的过程显示</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练过程中显示进度</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://kingpoem.github.io">王俊琦</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://kingpoem.github.io/2024/11/11/alchemist-1/">http://kingpoem.github.io/2024/11/11/alchemist-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://kingpoem.github.io" target="_blank">kingpoem的王国🏰</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a></div><div class="post_share"><div class="social-share" data-image="/./images/alchemist_1/cover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>请作者喝一杯咖啡</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/11/16/yank-paste/" title="你真的会 CV 吗"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/magician.png" onerror="onerror=null;src='/images/cover/cover_1.jpeg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">你真的会 CV 吗</div></div></a></div><div class="next-post pull-right"><a href="/2024/11/08/QQMusic-CLI-1-md/" title="QQMusic-CLI 开发日记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/cover/cover_1.jpeg" onerror="onerror=null;src='/images/cover/cover_1.jpeg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">QQMusic-CLI 开发日记</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/10/09/PPT/" title="PPT学习笔记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/PPT/zack.png" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-10-10</div><div class="title">PPT学习笔记</div></div></a></div><div><a href="/2024/11/08/QQMusic-CLI-1-md/" title="QQMusic-CLI 开发日记"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/cover/cover_1.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-20</div><div class="title">QQMusic-CLI 开发日记</div></div></a></div><div><a href="/2024/08/12/conda/" title="python 环境管理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/cover/cover_11.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-08</div><div class="title">python 环境管理</div></div></a></div><div><a href="/2024/08/10/git/" title="git"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/cover/git_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-22</div><div class="title">git</div></div></a></div><div><a href="/2024/10/28/matplotlib/" title="关于 matplotlib 的一点小事"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/matplotlib/playlist_2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-08</div><div class="title">关于 matplotlib 的一点小事</div></div></a></div><div><a href="/2024/07/18/network/" title="魔法原理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./images/cover/cover_3.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-08</div><div class="title">魔法原理</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/avatar.png" onerror="this.onerror=null;this.src='/images/cover/cover_1.jpeg'" alt="avatar"/></div><div class="author-info__name">王俊琦</div><div class="author-info__description">每个人都只有一个使命，那就是寻找自我，无论最终成为诗人还是疯子、先知还是罪犯。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kingpoem"><i class="fab fa-github"></i><span>关注我</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kingpoem" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">本网站采取滚动更新方式（小而频繁的更新），致力于让每篇文章都能反复回味。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NumPy"><span class="toc-number">1.</span> <span class="toc-text">NumPy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NDArray"><span class="toc-number">1.1.</span> <span class="toc-text">NDArray</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA"><span class="toc-number">1.2.</span> <span class="toc-text">创建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%90%88%E5%B9%B6"><span class="toc-number">1.3.</span> <span class="toc-text">修改合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E7%BB%84%E5%B1%9E%E6%80%A7"><span class="toc-number">1.4.</span> <span class="toc-text">获取数组属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E5%92%8C%E7%AD%9B%E9%80%89"><span class="toc-number">1.5.</span> <span class="toc-text">切片和筛选</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%89%E6%9D%A1%E4%BB%B6%E9%80%89%E6%8B%A9%E3%80%81%E6%9B%BF%E6%8D%A2%E6%95%B0%E6%8D%AE"><span class="toc-number">1.6.</span> <span class="toc-text">按条件选择、替换数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.7.</span> <span class="toc-text">数据保存和加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%BF%E6%92%AD"><span class="toc-number">1.8.</span> <span class="toc-text">广播</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"><span class="toc-number">1.9.</span> <span class="toc-text">线性代数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Einstein-Notation"><span class="toc-number">1.10.</span> <span class="toc-text">Einstein Notation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NumPy-%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%88%99"><span class="toc-number">1.11.</span> <span class="toc-text">NumPy 使用原则</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pandas"><span class="toc-number">2.</span> <span class="toc-text">Pandas</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E3%80%81%E8%AF%BB%E5%8F%96%E3%80%81%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.</span> <span class="toc-text">创建、读取、保存数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE"><span class="toc-number">2.2.</span> <span class="toc-text">数据访问</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="toc-number">2.3.</span> <span class="toc-text">数据清洗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F"><span class="toc-number">2.4.</span> <span class="toc-text">排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%88%E5%B9%B6"><span class="toc-number">2.5.</span> <span class="toc-text">合并</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Matplotlib"><span class="toc-number">3.</span> <span class="toc-text">Matplotlib</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Matplotlib%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">3.1.</span> <span class="toc-text">Matplotlib的核心概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Matplotlib%E7%9A%84%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.</span> <span class="toc-text">Matplotlib的常用函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%98%E5%9B%BE"><span class="toc-number">3.2.1.</span> <span class="toc-text">基本绘图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E5%9B%BE%E5%BD%A2"><span class="toc-number">3.2.2.</span> <span class="toc-text">动态更新图形</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3D-%E7%BB%98%E5%9B%BE"><span class="toc-number">3.2.3.</span> <span class="toc-text">3D 绘图</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Examples"><span class="toc-number">3.3.</span> <span class="toc-text">Examples</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch"><span class="toc-number">4.</span> <span class="toc-text">PyTorch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E5%86%85%E9%83%A8%E5%8F%98%E9%87%8F"><span class="toc-number">4.1.</span> <span class="toc-text">查看模型内部变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82%EF%BC%88nn-Linear%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">线性层（nn.Linear）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%88nn-Conv2d%EF%BC%89"><span class="toc-number">4.3.</span> <span class="toc-text">卷积层（nn.Conv2d）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%88nn-MaxPool2d%E3%80%81nn-AvgPool2d%EF%BC%89"><span class="toc-number">4.4.</span> <span class="toc-text">池化层（nn.MaxPool2d、nn.AvgPool2d）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88nn-ReLU%E3%80%81nn-Sigmoid%E3%80%81nn-Tanh%EF%BC%89"><span class="toc-number">4.5.</span> <span class="toc-text">激活函数（nn.ReLU、nn.Sigmoid、nn.Tanh）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88nn-BatchNorm2d%EF%BC%89"><span class="toc-number">4.6.</span> <span class="toc-text">批归一化层（nn.BatchNorm2d）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A2%E5%BC%83%E5%B1%82%EF%BC%88nn-Dropout%EF%BC%89"><span class="toc-number">4.7.</span> <span class="toc-text">丢弃层（nn.Dropout）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%88nn-ConvTranspose2d%EF%BC%89"><span class="toc-number">4.8.</span> <span class="toc-text">转置卷积层（nn.ConvTranspose2d）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%B1%82%EF%BC%88nn-Embedding%EF%BC%89"><span class="toc-number">4.9.</span> <span class="toc-text">嵌入层（nn.Embedding）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LSTM%E5%B1%82%EF%BC%88nn-LSTM%EF%BC%89"><span class="toc-number">4.10.</span> <span class="toc-text">LSTM层（nn.LSTM）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GRU%E5%B1%82%EF%BC%88nn-GRU%EF%BC%89"><span class="toc-number">4.11.</span> <span class="toc-text">GRU层（nn.GRU）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="toc-number">4.12.</span> <span class="toc-text">自定义层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96%EF%BC%88nn-AdaptiveAvgPool2d%EF%BC%89"><span class="toc-number">4.13.</span> <span class="toc-text">全局平均池化（nn.AdaptiveAvgPool2d）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Utils"><span class="toc-number">5.</span> <span class="toc-text">Utils</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#os-%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95%E6%93%8D%E4%BD%9C"><span class="toc-number">5.1.</span> <span class="toc-text">os - 文件和目录操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#join"><span class="toc-number">5.2.</span> <span class="toc-text">join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zip"><span class="toc-number">5.3.</span> <span class="toc-text">zip</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#swanlab"><span class="toc-number">5.4.</span> <span class="toc-text">swanlab</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pprint"><span class="toc-number">5.5.</span> <span class="toc-text">pprint</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tqdm"><span class="toc-number">5.6.</span> <span class="toc-text">tqdm</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scikit-learn"><span class="toc-number">6.</span> <span class="toc-text">Scikit-learn</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">6.1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">6.1.1.</span> <span class="toc-text">特征缩放和标准化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%88%AB%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81"><span class="toc-number">6.1.2.</span> <span class="toc-text">类别数据编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86"><span class="toc-number">6.1.3.</span> <span class="toc-text">缺失值处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">6.1.4.</span> <span class="toc-text">特征选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%A2%84%E6%B5%8B"><span class="toc-number">6.2.</span> <span class="toc-text">模型训练与预测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.1.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B"><span class="toc-number">6.2.2.</span> <span class="toc-text">预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.3.</span> <span class="toc-text">回归模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">6.3.</span> <span class="toc-text">模型评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.1.</span> <span class="toc-text">评估回归模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.2.</span> <span class="toc-text">评估分类模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ROC-%E6%9B%B2%E7%BA%BF%E5%92%8C-AUC"><span class="toc-number">6.3.3.</span> <span class="toc-text">ROC 曲线和 AUC</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E4%B8%8E%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">6.4.</span> <span class="toc-text">交叉验证与模型选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">6.4.1.</span> <span class="toc-text">K折交叉验证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%E8%B0%83%E5%8F%82"><span class="toc-number">6.4.2.</span> <span class="toc-text">网格搜索调参</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%90%9C%E7%B4%A2%E8%B0%83%E5%8F%82"><span class="toc-number">6.4.3.</span> <span class="toc-text">随机搜索调参</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">6.5.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="toc-number">6.5.1.</span> <span class="toc-text">主成分分析 (PCA)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90-LDA"><span class="toc-number">6.5.2.</span> <span class="toc-text">线性判别分析 (LDA)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">6.5.3.</span> <span class="toc-text">特征提取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">6.6.</span> <span class="toc-text">模型持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.6.1.</span> <span class="toc-text">保存模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.6.2.</span> <span class="toc-text">加载模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E9%81%93%E4%B8%8E%E7%BB%84%E5%90%88"><span class="toc-number">6.7.</span> <span class="toc-text">管道与组合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%AE%A1%E9%81%93"><span class="toc-number">6.7.1.</span> <span class="toc-text">使用管道</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95"><span class="toc-number">6.8.</span> <span class="toc-text">其他常见方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">6.8.1.</span> <span class="toc-text">特征重要性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%A6%82%E7%8E%87"><span class="toc-number">6.8.2.</span> <span class="toc-text">模型预测概率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%BE%E7%A4%BA"><span class="toc-number">6.8.3.</span> <span class="toc-text">训练模型的过程显示</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/./images/alchemist_1/cover.png')"><div id="footer-wrap"><div class="copyright">&copy;2024 By 王俊琦</div><div class="footer_custom_text">我渴望有人至死都暴烈地爱我，明白爱和死一样伟大，并永远站在我身边。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 't6qz5lUN2i19KNsgW39p76u8-gzGzoHsz',
      appKey: 'HlT3SpV7IKr8AoJnK1anKj9a',
      avatar: 'monsterid',
      serverURLs: 'https://t6qz5lun.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/calendar.js"></script><script src="/js/language.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>